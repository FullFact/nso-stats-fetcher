name: fetch-stats

on:
  schedule:
    # - cron: '0 10 * * *' # runs at 10:00 UTC everyday
    - cron: '5,35 6,7,8,9 * * 1-5' # runs at 5 and 35 past the hour UTC, Monday-Friday
    # this should catch ONS publications at 7am or 9:30am GMT or BST

  # Allow manual triggering of workflow
  workflow_dispatch:

jobs:
  fetch:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false  # if a scraper errors, the rest will keep running
      matrix:
        include:
          - country: uk
            index: cpi
          - country: uk
            index: cpih
          - country: uk
            index: rpi
          - country: ie
            index: cpi
          # - country: ar
          #   index: cpi
          - country: za
            index: cpi
          - country: za
            index: ppi
          - country: ng
            index: cpi
          # - country: mx
          #   index: cpi
          - country: jp
            index: cpi
    steps:
      - name: checkout repo content
        uses: actions/checkout@v4

      - uses: actions/setup-java@v3
        with:
          distribution: 'temurin'
          java-version: '17'

      - name: Install poetry
        run: pipx install poetry==1.8.5

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version-file: 'pyproject.toml'
          cache: 'poetry'

      - name: Install python dependencies
        run: poetry install --no-root

      - name: execute py script
        run: |
          poetry run python src/nsofetch/fetch_${{ matrix.country }}.py ${{ matrix.index }}
        env:
          PYTHONPATH: src
          PROXY_URL: ${{ secrets.PROXY_URL }}

      - name: Save scraper output
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.country }}-${{ matrix.index }}
          path: data/${{ matrix.country }}_inflation_${{ matrix.index }}.csv

  deploy:
    needs: [fetch]  # wait for the previous job to complete
    if: ${{ always() }}  # run even if the previous job fails
    runs-on: ubuntu-latest
    steps:
      - name: checkout repo content
        uses: actions/checkout@v4

      - name: Load scraper output
        uses: actions/download-artifact@v4
        with:
          path: artifacts

      - name: Move scraper output into place
        run: mv artifacts/*/* data

      - name: Add last updated timestamp
        run: |
          echo "Last updated: `date -u +"%Y-%m-%d %H:%M:%S"`" > status.txt

      - name: Commit files
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add -vA
          git commit -vm "update stats data" -a

      - name: Push changes
        uses: ad-m/github-push-action@master
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          branch: ${{ github.ref }}

      - name: Clean up artifacts
        uses: geekyeggo/delete-artifact@v2
        with:
          name: '*'
          failOnError: false

  # notify_on_failure:
  #   needs: [deploy]
  #   if: ${{ failure() }}  # run if anything before this point fails
  #   runs-on: ubuntu-latest
  #   steps:
  #     - name: Send a message to Slack if something went wrong
  #       uses: slackapi/slack-github-action@v2
  #       with:
  #         method: chat.postMessage
  #         token: ${{ secrets.SLACK_BOT_TOKEN }}
  #         payload: |
  #           channel: "${{ env.SLACK_CHANNEL_ID }}"
  #           username: "NSO stats fetcher"
  #           icon_emoji: ":chart_with_downwards_trend:"
  #           text: ":warning: Uh oh â€“ the NSO stats fetcher has errored :warning:"
